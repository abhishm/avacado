{
 "metadata": {
  "name": "",
  "signature": "sha256:6654a807925ca0e0ab7e9a3112bc89d1deb40b0e2cca2c2e7058513190cf01cc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. O = Over (finish all the supply of the previous week)\n",
      "2. ! = very few items left (less than one day supply)\n",
      "3. R =\tReplenish (less than desired amount of a week)\n",
      "4. N = Please dont you suck\t(greater than desired amount of a week)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Correction factor:**\n",
      "If the item is finished, then desired = desired*correction_factor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_consumption = 1\n",
      "max_consumption = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Formulating the problem as a Markov Decision Process**\n",
      "1. The state of the MDP is the number of item (tomato) in the store. \n",
      "2. We assume that a person can have maximum $N$ item in the store. In other word, if the person has $N$ items,  then we will not put any more item from our side. \n",
      "3. The action that we take is to put $x$ extra item in the store where $0\\leq x \\leq N$.\n",
      "4. For sake of an example, assume that the reward $r$ is a function of present state as following\n",
      "$$\n",
      "r(s) = \\left\\{\n",
      "\\begin{array}{cc}\n",
      "-10 & s=0 \\\\\n",
      "10 & 1 \\leq s \\leq 3\\\\\n",
      "-100 & s>3 \n",
      "\\end{array}\n",
      "\\right.\n",
      "$$\n",
      "5. Now we will use Q-Learning to solve this MDP."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "number_s = N+1\n",
      "number_a = N+1\n",
      "Q = -100*np.ones((number_s, number_a))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha = 0.1 #learning_rate\n",
      "epsilon = 0.1 # epsilon-greedy action"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def next_state(s,a):\n",
      "    c = np.random.randint(min_consumption, max_consumption+1)\n",
      "    return max(s+a-c, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def epsilon_greedy_action(s):\n",
      "    if epsilon < np.random.rand():\n",
      "        return np.random.randint(0,N-s+1)\n",
      "    else:\n",
      "        return np.argmax(Q[s,:N-s+1])   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reward(s):\n",
      "    if s == 0:\n",
      "        return -10\n",
      "    elif s >= 1 and s <= 3:\n",
      "        return 10\n",
      "    else:\n",
      "        return -100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_iter = 10000\n",
      "s = 0\n",
      "a = 0\n",
      "for _ in xrange(num_iter):\n",
      "    ns = next_state(s,a)\n",
      "    max_ns = np.max(Q[ns,0:N+1-s])\n",
      "    Q[s,a] += alpha*(reward(s)+max_ns -Q[s,a])\n",
      "    s = ns\n",
      "    a = epsilon_greedy_action(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "index 18 is out of bounds for axis 1 with size 11",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-9-e4f5af3b5d99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmax_ns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmax_ns\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon_greedy_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: index 18 is out of bounds for axis 1 with size 11"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "18"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argmax(Q,axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.around(Q,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argmax(Q,axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}