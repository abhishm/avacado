{
 "metadata": {
  "name": "",
  "signature": "sha256:a419bd7b634c35e7a481f38251e758fb39e61cdddc738532c156a166a93344c7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. O = Over (finish all the supply of the previous week)\n",
      "2. ! = very few items left (less than one day supply)\n",
      "3. R =\tReplenish (less than desired amount of a week)\n",
      "4. N = Please dont you suck\t(greater than desired amount of a week)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Correction factor:**\n",
      "If the item is finished, then desired = desired*correction_factor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_consumption = 1\n",
      "max_consumption = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Formulating the problem as a Markov Decision Process**\n",
      "1. The state of the MDP is the number of item (tomato) in the store. \n",
      "2. We assume that a person can have maximum $N$ item in the store. In other word, if the person has $N$ items,  then we will not put any more item from our side. \n",
      "3. The action that we take is to put $x$ extra item in the store where $0\\leq x \\leq N$.\n",
      "4. For sake of an example, assume that the reward $r$ is a function of present state as following\n",
      "$$\n",
      "r(s) = \\left\\{\n",
      "\\begin{array}{cc}\n",
      "-10 & s=0 \\\\\n",
      "10 & 1 \\leq s \\leq 3\\\\\n",
      "-100 & s>3 \n",
      "\\end{array}\n",
      "\\right.\n",
      "$$\n",
      "5. Now we will use Q-Learning to solve this MDP."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "number_s = N+1\n",
      "number_a = N+1\n",
      "Q = -100*np.ones((number_s, number_a))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha = 0.1 #learning_rate\n",
      "epsilon = 0.1 # epsilon-greedy action"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def next_state(s,a):\n",
      "    c = np.random.randint(min_consumption, max_consumption+1)\n",
      "    return s+a-c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def epsilon_greedy_action(s):\n",
      "    if epsilon < np.random.rand():\n",
      "        return np.random.randint(0,N-s+1)\n",
      "    else:\n",
      "        return np.argmax(Q[s,:N-s+1])   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reward(s):\n",
      "    if s == 0:\n",
      "        return -10\n",
      "    elif s >= 1 and s <= 3:\n",
      "        return 10\n",
      "    else:\n",
      "        return -100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_iter = 10000\n",
      "s = 0\n",
      "a = 0\n",
      "for _ in xrange(num_iter):\n",
      "    ns = next_state(s,a)\n",
      "    max_ns = np.max(Q[ns,0:N+1-s])\n",
      "    Q[s,a] += alpha*(reward(s)+max_ns -Q[s,a])\n",
      "    s = ns\n",
      "    a = epsilon_greedy_action(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argmax(Q,axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "array([3, 3, 3, 3, 1, 3, 3, 3, 2, 1, 1], dtype=int64)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.around(Q,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "array([[-101.  , -101.9 , -100.68, -100.  , -100.  , -101.  , -101.  ,\n",
        "        -100.  , -102.71, -101.  , -101.  ],\n",
        "       [ -98.1 ,  -99.  ,  -95.4 ,  -94.24,  -91.48,  -98.1 ,  -98.1 ,\n",
        "         -95.9 ,  -98.1 ,  -98.1 , -100.  ],\n",
        "       [ -88.35,  -94.49,  -94.35,  -96.61,  -94.78,  -93.49,  -97.29,\n",
        "         -95.9 ,  -96.56, -100.  , -100.  ],\n",
        "       [ -83.58,  -82.86,  -81.75,  -91.5 ,  -92.29,  -91.85,  -91.85,\n",
        "         -91.85, -100.  , -100.  , -100.  ],\n",
        "       [-184.11, -236.9 , -236.24, -199.13, -198.52, -199.62, -199.03,\n",
        "        -100.  , -100.  , -100.  , -100.  ],\n",
        "       [-240.95, -289.43, -244.25, -200.  , -200.  , -200.  , -100.  ,\n",
        "        -100.  , -100.  , -100.  , -100.  ],\n",
        "       [-290.23, -300.  , -269.5 , -200.  , -200.  , -100.  , -100.  ,\n",
        "        -100.  , -100.  , -100.  , -100.  ],\n",
        "       [-300.  , -300.  , -234.11, -200.  , -100.  , -100.  , -100.  ,\n",
        "        -100.  , -100.  , -100.  , -100.  ],\n",
        "       [-345.77, -348.64, -252.22, -100.  , -100.  , -100.  , -100.  ,\n",
        "        -100.  , -100.  , -100.  , -100.  ],\n",
        "       [-421.43, -478.51, -100.  , -100.  , -100.  , -100.  , -100.  ,\n",
        "        -100.  , -100.  , -100.  , -100.  ],\n",
        "       [-100.  , -100.  , -100.  , -100.  , -100.  , -108.14, -108.67,\n",
        "        -100.  , -100.  , -110.  , -100.  ]])"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argmax(Q,axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "array([3, 4, 0, 2, 7, 6, 5, 4, 3, 2, 0], dtype=int64)"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}