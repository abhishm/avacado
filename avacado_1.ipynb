{
 "metadata": {
  "name": "",
  "signature": "sha256:f324b1e1ab11d6f48b1f4f6ecfe912c44c561a679d7d5d4cbc99612c72b732ec"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. O = Over (finish all the supply of the previous week)\n",
      "2. ! = very few items left (less than one day supply)\n",
      "3. R =\tReplenish (less than desired amount of a week)\n",
      "4. N = Please dont you suck\t(greater than desired amount of a week)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Correction factor:**\n",
      "If the item is finished, then desired = desired*correction_factor"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Formulating the problem as a Markov Decision Process**\n",
      "1. The state of the MDP is the number of item (tomato) in the store. \n",
      "2. We assume that a person can have maximum $N$ item in the store. In other word, if the person has $N$ items,  then we will not put any more item from our side. \n",
      "3. The action that we take is to put $x$ extra item in the store where $0\\leq x \\leq N$.\n",
      "4. For sake of an example, assume that the reward $r$ is a function of present state as following\n",
      "$$\n",
      "r(s) = \\left\\{\n",
      "\\begin{array}{cc}\n",
      "-10 & s=0 \\\\\n",
      "10 & 1 \\leq s \\leq 3\\\\\n",
      "-100 & s>3 \n",
      "\\end{array}\n",
      "\\right.\n",
      "$$\n",
      "5. Now we will use Q-Learning to solve this MDP."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_consumption = 0\n",
      "max_consumption = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "number_s = N+1\n",
      "number_a = N+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha = 0.1 #learning_rate\n",
      "epsilon = 0.1 # epsilon-greedy action"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def next_state(s,a):\n",
      "    c = np.random.randint(min_consumption, max_consumption+1)\n",
      "    return max(s+a-c, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def epsilon_greedy_action(s):\n",
      "    if epsilon < np.random.rand():\n",
      "        return np.random.randint(0,N-s+1)\n",
      "    else:\n",
      "        return np.argmax(Q[s,:N-s+1])   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reward(s):\n",
      "    if s == 0:\n",
      "        return -10\n",
      "    elif s >= 1 and s <= 3:\n",
      "        return 10\n",
      "    else:\n",
      "        return -100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_iter = 1000000\n",
      "s = 0\n",
      "a = 0\n",
      "Q = -100*np.ones((number_s, number_a))\n",
      "for _ in xrange(num_iter):\n",
      "    ns = next_state(s,a)\n",
      "    max_ns = np.max(Q[ns,0:N+1-s])\n",
      "    Q[s,a] += alpha*(reward(s)+max_ns -Q[s,a])\n",
      "    s = ns\n",
      "    a = epsilon_greedy_action(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Optimal Action\n",
      "for i in xrange(Q.shape[0]):\n",
      "    print 'The optimal action for state {} is {}'.format(i, np.argmax(Q[i,:N-i+1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The optimal action for state 0 is 3\n",
        "The optimal action for state 1 is 2\n",
        "The optimal action for state 2 is 1\n",
        "The optimal action for state 3 is 0\n",
        "The optimal action for state 4 is 0\n",
        "The optimal action for state 5 is 1\n",
        "The optimal action for state 6 is 1\n",
        "The optimal action for state 7 is 3\n",
        "The optimal action for state 8 is 2\n",
        "The optimal action for state 9 is 1\n",
        "The optimal action for state 10 is 0\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    }
   ],
   "metadata": {}
  }
 ]
}